# llm_prompt_rephrase_message_rag
Quick tool to kinda permute/bruteforce few combinaisons of model/prompts/contexts to evaluate each and see if the llm can rephrase the last user message to be used in a RAG context
